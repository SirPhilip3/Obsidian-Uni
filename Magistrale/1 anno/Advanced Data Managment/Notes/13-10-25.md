mongo db 

document db 

designed for a distributed deployment + high performance 
document can be trasformed in various data model -> document similar to a tree 

mongodb -> query -> find something similar to what i'm loking four -> giving a partial document -> query by example 

base propieties -> 
+ basically available 
+ soft state 
+ eventually consistent -> after an update at some point it will be known to everyone makes sense in a distributed setting -> noone needs to wait for the write to be final -> depends on use case -> ex for reservation not good -> real consistency / bank account -> if it's managing socials we don't care 

use cases -> 
there is no join
no transaction
- everything on a document

example : 
we want to store location + user generated comments 
we want to find nearby location
record checkin
generate stats about check in -> if we wont stast for users and locations -> another collectios

```json
location1 = {
	name : "name1",
	address : "via gioia 12",
	city : "Roma",
	zip : "34112",
	
	tags : ["bussines","villa"],
	latlog : [42.0, 72.2],
	
	tips : [
		{user:"josh", time: 07/23/23, tip : "test ts  s "}
	]
}
```

```
db.location.find({zip: "34112", tags : "villa"})
```

mongodb not suitable for gis data but can calculate disance with euclidian distance if we suppose the are on a plane or in a sphere > distance in a sphere

we need to know the shape of  ... -> approximated to elipsoid -> coords approx of 2 meters

for mongo -> partial schema -> with indexes , makes more efficient searching for something :
```
db.locations.ensureIndex({latlong : "2d"})
```

different kind of indexes , 2d = 2d index -> we can use spatial operator 

```
db.locations.find({latlong : {$near : [40,70]}})
```

tips -> list of documents

insert
```
db.locations.insert(place1)
```

update
```
db.locations.update({name : "10"}, {$push:{tip : {...}}})
```

checkin 

```json
user1 = {
	name: "opopas" ,
	
	checkins : ["name1","name2"]
}
```

or we can use objectid and manage the checkins seperatly -> propieties only to the checkin collection fine otherwise it get's complicated we need to specify how to aggregate data 
like this we can have an index with the checkins of a determined user

almost mundatory to think of the data with clear idea on the operations you want to perform

`.sort({ts:-1}).limit(10)`

---
aggregation pipeline / map reduce

more complex stats -> aggregation -> we need to write the execution plan of an aggregation

several stagest -> each processes the result of the previous one -> linear -> not a graph , each stage a name that idenifiy the function : ex match -> filter  
total summing the amount of the document belonging to the same group
`$match : ($status : "A")`
new id for all the mmenber that belong to the same group 
`_id : "$custm_id", total : {$sum : "$amount"}` 

in general transformation pipeline

stages : group , match , project (how the result is structured), sort , limit , skip (drops docs from the beginning of a collection) , unwind (gets a list and explodes the content of that list) , geonear (similar to near but in aggregation pipeline + more params)

in each stage we can use operators : sum , push , std , average

unwind -> way to explode content of a list obtaining docs that replicate the rest of the documents 
1 docs with checkin that is first in the list , another that is the second with replicated other values

bucket aggregation -> similar to group by but for numerical valueswe can define boundaries of the data 

instead of counting we sum 1 for each element

join -> lookup -> its like left join only used in the pipeline -> doesnt work in dist settigns well

we can store the result of an aggregation pipeline with \$out without returning it tot the user
merge 
unions

more efficent to calculate distance respect to order by distance -> bc all the stages are always executed if we don't indicate that we will discard something later it will remain there -> no opt between stages 

mapReduce -> by declaring functions that pu tihngs togheter and mat function that will 
mapfunction , reducefunction 

mapreduce less efficent that aggregation pipeline

lookup -> with is the local and foreingfield and put them togheter

recursive aggregation 

