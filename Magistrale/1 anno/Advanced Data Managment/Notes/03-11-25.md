aggregate are implicit in opencypher -> aggregation in the return statements 

```cypher
MATCH (n{name:'john'}) - [:FRIEND] - (friend)
Return n, COUNT(friend) // return friend count

// count number of friend for any general node :
MATCH (n) - [:FRIEND] - (friend)
Return n, COUNT(friend) // group by n and count friend

// users with highest number of frinds or at least 10 friend (HAVING in SQL) 
// with
MATCH (n) - [:FRIEND] - (friend)
WITH n , count(friend) AS fcount // its like a barrier that we can use to set condition on what was available before 
WHERE fcount > 10 
RETURN  n , fcount

MATCH (n) - [:FRIEND] - (friend)
WITH n , count(friend) AS fcount 
ORDER BY fcount // DESC > reverses the sorting order
LIMIT 3 // 3 user wit smallest number of friends 
// theres also SKIP to skip first n elements 
WHERE fcount > 10 
RETURN  n , fcount

// unwind , process content of a list in a way similar to the way we process tuples 
NAME:'claudio' , PLACES:['PL1','PL2','PL3']
// unWIND -> 3 tuples 
Name:'claudio' , places:'pl1'
Name:'claudio' , places:'pl2'

// unwind the list do some work and repack the list
unwind [1,2,3] as x
return x 

with [1,1,2,2,3,3] as coll
unwind coll as x // gave a name to the collection
distinct x 
return x // still returns 3 tuples separated 
return collect(x) as set // returns a list of distinct elements 

unwind $events as event // events from external variable
merge (y : year {year : event.year}) // merge a node with type year and has a propiety year and has the same value as the event , if it does not exists it will create a node 
merge (y) <- [:IN] - (e : event {id : event.id})
// we create relationship between the event and the node created ?
return e.id as x 
order by x 
```

```cypher
create(n)
create(n:person{name:'mario'}) - [:friend]-(a:person{name:'alice'})
return id(n) // everytime we execute this different 

match (a:person), (b:person)
where a.name = 'nodeA' and b.name = 'nodeB'
create (a)-[r:RELTYPE{name.a + '<-->' + b.name}] -> (b) 
return r 

// name.a + '<-->' + b.name something computed at time of the creation
// if already executed than fail since reltype already exists
// a and b not created since bound to variables 
// what is created is the thing that is not known at the time of create 
```

delete a node -> first match and than delete 
```cypher
Match (n:dellme)
delete n // if n has some connection the delete will fail

// first delete relationship
match (n:dellme) - [r] -()
delete r 
match (n:dellme)
delete n 

// or we can use detach 
match (n:dellme)
detach delete n  // removes all relationship also
```

update 
```cypher
match (n:person {name:'claudio'})
set n.lastseen = now()
```

for each person have an attribute with number of friends 
```cypher
MATCH (n:person) - [:FRIEND] - (friend)
WITH n , count(friend) AS fcount 
set n.friendcount = fcount
return count(n) as updated
```

opposite of *set* > *unset* 
```cypher
match (p:person)
where p.login_date < today
remove p.login_date
```

merge -> if part of the patter does not exists the whole pat will be created again 
```cypher
merge (p.person{name:'N'}) -[:friend]- (p2:person{name:'b'})
// if p2 does not exist p will be created again even if it was already present
```

--- 
distributed databases 

scalabity -> up bigger machines , out more smaller machines 

managin tables more difficult in distributed setting
transparent to the user 

address the data indepently on where its store , we shouldn know where the data is stored , data may be replicated to make access faster 

data maybe fragmented 

what can go wrong : 
+ failure of one component hardware / service
+ communication failure
+ network partition ->network partition and server failures are indistinguishible