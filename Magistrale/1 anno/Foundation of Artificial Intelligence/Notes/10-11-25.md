generalization 

if all the points are in a give radius and ....

than the maximum number of mistakes that we can do is the following : 
$$
k \le \frac{R^2 ||w^*||^2}{\gamma^2}
$$
gamma is a mesure dependent on the scale of the classifier 

geometric margin -> how far away we are from the 2 

macimum number of steps grows ^2 

finding the margin -> makes for an easier problem -> perceptron doesnt try to mamke the margin larger 

svm > tries to find the larger margin possible between the classes 

points on the margin 
at least n+1 oo the margin

the one that maximises the margin -> best , reduced variance -> only points on the margin will help with the variance

we can set the minimum margin to whatever we want -> in the scale of $w$ 

we want to maximize $2/||w||$ or minimize $||w||^2$ 

lagrangian ???? 
we only see the dot prodact of $x_i \cdot x_j$
1 variable per data point 

dimensionality of the problem needs to be less than the number of points 

only 2 points define the support vector in 2d the other point do not contribute 

svm still date needs to be linearly separable 

relax : 
+ allow misscalssification
+ allow non linear boundaries 

if a point is not getting classified alphas will go to inf

allow misscalssifiaction ->marging always >= 1 we add a new variable z that will let us go lower to 1 but we penalize that in the minimization 
$$
\min_w \frac{1}{2}||w||^2 + C \sum_i \zeta_i
$$

as  C to inf -> back to no miss class allowed 
if them argin <