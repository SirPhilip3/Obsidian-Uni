convolution 

shift invariance -> can be used in 1d data > timeseries 

pooling operator -> combines sampling > to reduction in dimensionality 

3x3 convolution -> mask superimposed on the image -> product of each poin image with each in the max and sum becomes new pixel 

use to have connecctivity of the object behind the mask -> keeps local influence -> also keeps translation invariant

a mask for each colours (channels) 

right size of the mask is mostly problem dependet 
increase in resolution = increase in mask size 

use padding in order to have same spatial dimensionality as before 

strides -> increase step size for the convolution operator

pooling ->
max -> return the max of the pooling units
average -> returns the average
sum -> return the sum 

alexnet , vgg16

resnet -> in order to make it so the training of a deep network gets easier -> response at the end is the difference between the result at the previous level -> training on the delta 

we need less steps 

transfer learning -> lower levels learn something more universal we can than create more specific classifier 