inductive reasoning 

be able to predict the feature given information about the past 

we dont want to memorize the data but predict , generalize the data 
simpler function better 

supervised learning -> in the training set all the instance of a problems are classifed with the correct label 

rule to separate the various domain 

usupervised -> we dont have label on the training 

reinforcment learning -> we have feedback an agent interacting with the environment obtains reward / punishment for theyr action it learn to follow the path of max reward

X -> set of possible imputs Y -> possible outputs 
2 random varaibles with some dependency the joint prob distribution is unknown 

trainig set are set of tuplas sampled from X and Y

the learning algorithm is a mapping between X x Y and the hypotesis H 
and we select a function $f_s$ such that $f_s(x) \approx y$ 

generalization a model that predicts new data -> not all errors are the same 

let V be a loss function that indicates the penalty for a wrong prediction 
the expected / true error : 

we can't know this since we dont know the joint distribution

empirical error -> average over the training set for the loss 

condition for generalization -> regardless of theg joint distr -> the average error converges as the trainig set grows to the true error of the function 

a polynomial perfectly interpolates the empirical data -> always 0 -> expected error not 0  -> 

if i dont have bound on hyotesis space i can laways create new functions that keep the empirical error = 0 -> function must constantly vary 

if f overfits what i observe in after the training set it will not reflect the true error 

control of complexity 