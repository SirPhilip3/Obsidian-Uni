changing theta chenages the lowerbound of the log likelihood 

bernulli mixture 

we have d independent binary variable for each class 

pixel are correlated in respect to a particular class -> not necessarily true 

generaive model 

---
*mean shift* 

non parametric model that extract classes 

each centere of density will give us a class 

chose initial window size choose initial loc and go towars the baricenter repeat until fix point -> class 

kenels -> circle , square , normal , uniform 

mean shift -> moves with distance given by gradient / density -> low density > greater step otherwise smaller steps 

algo always converges 

will no need any assumption no the shape of the data 

distance is dependant on the data that is rapresented 

for points -> euclidean

instead of distances use hierarchical clustering -> data into trees where lower level more similar 

aaglomerative clustering > merge 2 at a time until we have only one 

mesuring similarity linkage mesures 