density estimators 

can we estimate the density without 

we can make a monte carlo estimation of the probability P = k/n 

use histograms -> count and partition the space in regions that are disjoint 
what if we have mixed data in the region 

perzel windows -> we dont pre partition the space , we can have adifferent region for every x 

h = size parameter 

window >only looks at distance h from the space 

put a gaussian centered on each particular xi and than average it out to get the final density  

function is a smoothing of the impulses on the xi 

convolution theorem 

FT(f\*g)(u) = FT(f)(u) \* FT(g)(u)

how to chose h 

wtf is K(x) -> risk ??? 

c1 -> statistical moment 
c2 -> the square of K 
c3 -> the integral of f''(x)^2  -> this depends on the underlying prob dist -> we dont know this -> we can use cross validatio , solve the equation 

there is no training cost -> at training time we just store data 

regoins may be different from each point 

balancce between size and speed -> if we get higher density -> smaller regions -> lower density larger regions 

K can be fixed (number of samples) -> i want that number of samples -> grow spherical region until it contains k points -> so the volume R can change

KNN

region is adapted -> sampling window is adapted k=1 > infinities at the location of the sample points -> radius = 0 

k=5 -> rule of thumb does not depend on the scale of the problem 

if number of samples to infty -> and number of neighbors k to nÃ¬infinity but slower in respect to 

than we can get reasonably nea the real density

knn classifier 

look at closest point in the dataset and assign to the point we are looking at that class 

creates voronoi tasselation of the region 

knn -> we look instead of 1 k neighbors and we assign the class in respect to the majority vote

if k converges slower than n than we reach perfect classifier 
there is no training only storage 

as dimensionality increases also the difficulty increases -> all points are far away from one another and almost all are near the boundaries 

1 volume (distance 1 from the center) of a ball of n dimension 
1st dimension -> vol = 2 -> line between -1 and 1 
2nd vol > phi 
3nd vol > 4/3 phi
volume decreases to 0 
lenght of diagonal in n dimension of a cube sqrt 2 -> sqrt of n in in n dimension but the sphere is goin to extend up to 1 

9 dim the readius eq to the > infinite dim will be infinte in size 

radius of the tangent circles sqrt(n)/n -1/n
curse of dimensionality 
learning high dimensional data is difficult 

