generative classifiers

now classifier needs only to decide to which class associate an object 

descriminative learning algo -> trained to descriminate from a given number of classes

generative learning algo -> probability of the feature given the class 

we model p(x|y) and p(y) -> y in general a set of classes 

we can have bayes to get c

we can avoid computing p(x) -> since 

difference -> given two classes -> in the discriminative distrivution is more complicated for the two 
 
generative become more complex requireim more data -> we need to come up with the characteristics of each class -> some char are not realted to the other class and not used to discriminate the two 

if we give them a new class -> generative can easly reject an option since it will not have any of the characteristics 

we can just add classifier for this new class 

discirminate we need to decide at priori the class to discriminate 

each variable will be a gaussian with all the same common covariance -> same error for all =?=?

log likelihood 

only prob of y depends on phi 

naive bayes for text -> rapresent a text in vector space and rapresent a text as number of times that we see a word 

but is also important to know the order 

ex p_spam = 0.2 , p_ham=0.8 , p_sale|spam = 0.9 , p_sale|ham = 0.2, p_price|spam = 0.8 p_price|ham = 0.3

p_sale
p_price 
P_sale,price if different form p_sale * p_price -> than not independent 

p_sale = $p(sale|spam)*p(spam) + p(sale|ham)*p(ham)$ = 0.9 \* 0.2 + 0.2 \* 0.8 = 0.34 
p_price = $p(price|spam)*p(spam) + p(price|ham)*p(ham)$ = 0.8 \* 0.2 + 0.3\* 0.8 = 0.4

p_sale \* p_price = 0.13

$p(sale,price) =p(sale,price|spam)p(spam)+ p(sale,price|ham)p(ham) = p(sale|spam)p(price|spam)p(spam) + p(sale|ham)p(price|ham)p(ham) =0.192$ since its different sale and price are not indipendent even if are independent in spam and ham emails independently 

parametric generative classifier 

unbias estimator mean = value that we want to estiamate 
naive bayes -> asintotically unbiased  

1/n-1 sum i=1 n x_i - bar x^2 -> unbiased variance estimator 
where bar x is the average unbiased estimator 

the distribution assumption is important -> good if data well approximated to that distribution 