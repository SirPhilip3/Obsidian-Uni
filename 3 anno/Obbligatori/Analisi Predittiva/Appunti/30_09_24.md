---
creation: 2024-09-30T10:18:00
tags:
  - appunti
---
Principio di simulazione 

dove variabilità di x è minore -> errore è maggiore (variabilità è al denominatore) 

meno incertezza possibile in $\bar X$ -> so che la retta deve passare per di la , predizione molto distante dalla media -> maggiore errore

quale potrebbe essere variabilità maggiore della predizione -> più distanti siamo dalla media 

LS^2 -> minimizza i quadrati degli errori 

divisione per n-2 in standard error 
$$\frac{1}{n-2}\sum(y_i+ (\beta_0 + \beta_1X)^2)$$
somma degli errori al quadrato (risduals-> ciò che rimane dopo la stima)

**Advertising data**

varianza molto elevata 

$e_i$ versione empirica dell'errore
$$y_i = \hat\beta_0 + \hat\beta_1x_i+ e_i$$
verificare che la varianza sia costante con i residui ( omoschedasticità )

per spiegare come si comporta y :
+ y cambia in funzione di x
+ y non cambia in funzione di x -> sintetizzata in y medio 

se aggiungo x ci fa spiegare qualcosa rispetto a non averlo

residui con solo $\bar y$ = $\sum(y_i - \bar y)^2 = SS_{tot}$

$\sum e_i^2 = SS_{res}$ dei residui  

$\sum(\hat y_i -\bar y)^2 = SS_{reg}$ SS regression qunato è distante la retta della regressione dalla media

$SS_{tot}$ -> voglio dividerla in distanza dalla retta media a la distanza dei punti dalla retta osservata 

somma dei residui = 0 per def 

$R^2$ quanto di y 