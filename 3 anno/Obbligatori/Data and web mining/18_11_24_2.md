---
creation: 2024-12-03T10:14:00
publish: true
---
# Clustering Evaluation

## Intrinsic Evaluation

Quando non abbiamo nessuna indicazione di cosa è corretto la valutazione del clustering viene detta *intrinseca* ( questo è il caso tipico )

Visto che non abbiamo le *label* dobbiamo usare una misura basata sulla *distanza* 

Per determinare la bontà di un cluster utilizziamo la **silhouette coefficent** 
Questo è determinato da due misure di distanza dove , per ogni oggetto $o_i$ di un cluster $C_h$ : 
+ **intra-class similarity** :
	+ $a(o_i) = \frac{\sum_{o_j \in C_h, i \neq j} dist(o_i, o_j)}{|C_h|-1}$
	+ Ossia la media delle distanze tra tutti i punti del cluster deve essere minima 
+ **inter-class dissimilarity** :
	+ $b(o_i) = \min_{C_k \neq C_h}\bigg\{\frac{\sum_{o_j \in C_k} dist(o_i, o_j)}{|C_k|}\bigg\}$
	+ Ossia che la minima distanza da un'altro cluster sia massima

Possiamo quindi definire il **silhouette coefficent** per $o_i$ come : $s(o_i) = \frac{b(o_i)-a(o_i)}{\max\{ a(o_i),b(o_i) \} }$
Questo sarà compreso tra $-1$ e $1$ dove $1$ rappsenta il miglio clustering possibile 

Possiamo trovare il **silhouette coefficent** per l'intero *clustering* facendo la media dei **silhouette coefficent** per ogni singolo oggetto del dataset

>[!example]
>![[Pasted image 20241203114845.png]]
>
>Attraverso il **silhouette coefficent** possiamo trovare il numero cluster $k$ 
>>[!note] 
>>E' meglio prendere un numero di cluster maggiore in modo che siano più coesi tra di loro
## Extrinsic Evaluation

Quando abbiamo qualche indicazione di correttezza 

>[!note] 
>Questo avviene per dataset che sono composti di dati sintetici o dataset piccoli per i quali è stato possibile fare il labeling manuale delle istanze
>

+ Sia $C(o_i)$ l'id del cluster dati dall'algoritmo di clustering per un oggetto $o_i$
+ Sia $L(o_i)$ la *true clustering label* per un oggetto $o_i$

Possiamo costruire la seguente *tabella di contingenza*

|                     |                                     Same Cluster                                     |                                   Different Cluster                                    |
| :-----------------: | :----------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------: |
|   **Same Label**    |  # True Positive $TP = \| \{o_i,o_j \| C(o_i) = C(o_j) \land L(o_i) = L(o_j)\} \|$   |  # Falsi Negativi $FN = \|\{o_i,o_j \| C(o_i) \neq C(o_j) \land L(o_i) = L(o_j)\} \|$  |
| **Different Label** | # Falsi Positive $FP = \|\{o_i,o_j \| C(o_i) = C(o_j) \land L(o_i) \neq L(o_j)\} \|$ | # True Negative $TN = \|\{o_i,o_j \| C(o_i) \neq C(o_j) \land L(o_i) \neq L(o_j)\} \|$ |
Dove : 
+ **Positive** : Agli oggetti gli era stato assegnato lo stesso *cluster* 
+ **Negative** : Agli oggetti gli era stato assegnato un *cluster* differente
+ **True / False** : La decisione si allinea o no con la label data in input

Possiamo quindi trovare le seguenti statistiche : 
**Rand Statistic** :
$$\frac{TP + TN}{TP + FP + TN + FN}$$
>[!note] Explanation
Misura il numero di paia di oggetti per cui un abbiamo preso una decisione di clustering corretta 

>[!warning] 
>Quando il numero di *classi* e *cluster* è grande allora il numero di *True Negative* aumenta e potrebbe falsare la *Rand Statistic*

**Jaccard Coefficent** : 
$$\frac{TP}{TP+FP + FN}$$
>[!note] Explanation
>Non considera i *True Negative*

# Artificial Neural Networks 