---
creation: 2024-12-03T10:14:00
publish: true
---
# Clustering Evaluation

## Intrinsic Evaluation

Quando non abbiamo nessuna indicazione di cosa è corretto la valutazione del clustering viene detta *intrinseca* ( questo è il caso tipico )

Visto che non abbiamo le *label* dobbiamo usare una misura basata sulla *distanza* 

Per determinare la bontà di un cluster utilizziamo la **silhouette coefficent** 
Questo è determinato da due misure di distanza dove , per ogni oggetto $o_i$ di un cluster $C_h$ : 
+ **intra-class similarity** :
	+ $a(o_i) = \frac{\sum_{o_j \in C_h, i \neq j} dist(o_i, o_j)}{|C_h|-1}$
	+ Ossia la media delle distanze tra tutti i punti del cluster deve essere minima 
+ **inter-class dissimilarity** :
	+ $b(o_i) = \min_{C_k \neq C_h}\bigg\{\frac{\sum_{o_j \in C_k} dist(o_i, o_j)}{|C_k|}\bigg\}$
	+ Ossia che la minima distanza da un'altro cluster sia massima

Possiamo quindi definire il **silhouette coefficent** per $o_i$ come : $s(o_i) = \frac{b(o_i)-a(o_i)}{\max\{ a(o_i),b(o_i) \} }$
Questo sarà compreso tra $-1$ e $1$ dove $1$ rappsenta il miglio clustering possibile 

Possiamo trovare il **silhouette coefficent** per l'intero *clustering* facendo la media dei **silhouette coefficent** per ogni singolo oggetto del dataset

>[!example]
>![[Pasted image 20241203114845.png]]
>
>Attraverso il **silhouette coefficent** possiamo trovare il numero cluster $k$ 
>>[!note] 
>>E' meglio prendere un numero di cluster maggiore in modo che siano più coesi tra di loro
## Extrinsic Evaluation

Quando abbiamo qualche indicazione di correttezza 

>[!note] 
>Questo avviene per dataset che sono composti di dati sintetici o dataset piccoli per i quali è stato possibile fare il labeling manuale delle istanze
>

+ Sia $C(o_i)$ l'id del cluster dati dall'algoritmo di clustering per un oggetto $o_i$
+ Sia $L(o_i)$ la *true clustering label* per un oggetto $o_i$

Possiamo costruire la seguente *tabella di contingenza*

|                     |                                     Same Cluster                                     |                                   Different Cluster                                    |
| :-----------------: | :----------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------: |
|   **Same Label**    |  # True Positive $TP = \| \{o_i,o_j \| C(o_i) = C(o_j) \land L(o_i) = L(o_j)\} \|$   |  # Falsi Negativi $FN = \|\{o_i,o_j \| C(o_i) \neq C(o_j) \land L(o_i) = L(o_j)\} \|$  |
| **Different Label** | # Falsi Positive $FP = \|\{o_i,o_j \| C(o_i) = C(o_j) \land L(o_i) \neq L(o_j)\} \|$ | # True Negative $TN = \|\{o_i,o_j \| C(o_i) \neq C(o_j) \land L(o_i) \neq L(o_j)\} \|$ |
Dove : 
+ **Positive** : Agli oggetti gli era stato assegnato lo stesso *cluster* 
+ **Negative** : Agli oggetti gli era stato assegnato un *cluster* differente
+ **True / False** : La decisione si allinea o no con la label data in input

Possiamo quindi trovare le seguenti statistiche : 
**Rand Statistic** :
$$\frac{TP + TN}{TP + FP + TN + FN}$$
>[!note] Explanation
Misura il numero di paia di oggetti per cui un abbiamo preso una decisione di clustering corretta 

>[!warning] 
>Quando il numero di *classi* e *cluster* è grande allora il numero di *True Negative* aumenta e potrebbe falsare la *Rand Statistic*

**Jaccard Coefficent** : 
$$\frac{TP}{TP+FP + FN}$$
>[!note] Explanation
>Non considera i *True Negative*

# Artificial Neural Networks 

**ANN** ( *Artificial Neural Networks* ) vogliono imitare il funzionamento del cervello umano 
## Artificial Neuron

Il loro componente fondamenteale è un **Artifical Neuron** , questo è formato da : 
+ Una *funzione* ( $f(x)$ ) all'interno del corpo del neurone 
+ Riceve vari *input* ( da altri neuroni )
+ Produce un output , questo sarà inviato ai prossimi neuroni

>[!example] 
>![[Pasted image 20241204101635.png]]

>[!warning] 
>Se i neuroni avessero tutti la stessa $f(x)$ non potrebbero imparare nulla di interessante 

## Artificial Neural Network

Possiamo collegare gli **artifical neuron** attraverso **sinapsi** , nel caso più semplice l'output del *neurone* viene forwardato a tutti i *neuroni* vicini a lui

>[!example] 
>![[Pasted image 20241205084759.png]]

## Brain Training

Per allenare una **ANN** seguiamo i seguenti passi : 
+ Un'istanza di training è presentata all'*algoritmo di machine learning* 
+ L'algoritmo produce una **predizione** per quell'istanza
+ La differenza tra la *predizione* e l'output desiderato è detta **loss**
+ La **loss** è usata per aggiornare i parametri o **weights** dell'algoritmo di machine learning 
>[!note] 
>Questo viene detto **back propagation** 
+ Il feedback che dà la *loss* viene pesato da un **learning rate** ( più piccolo è più cauti saranno gli step )
+ Ripeti su tutto il **training dataset** 
+ Ripeti tutto il processo più volte ( ogni volta che esploriamo l'intero dataset viene detta **epoca** )
## Hyperparameters

I parameti che dobbiamo decidere all'interno di una **ANN** sono i seguenti : 
+ Che **funzione** usare dentro i *neuroni* ?
+ Come collegare i neuroni ? 
+ Come valutiamo la goodness della nostra predizione ?