---
creation: 2024-09-24T15:30:00
publish: true
---
# Supervised Learning 

Il *supervised learning* applicato alla **Classificazione** è uno dei più semplici algoritmi di *machine learning* 

Avremo in *input* dei dati tabellari 

Ogni riga della tabella viene detta **Record** , ognuna contiene informazioni riguardanti una certa *istanza* di un *oggetto* 

Ogni **Record** è *identificato* dalle **Features** ( le *colonne* della tabella ) 

>[!example]
>| Student | IAP | BD  | ASD |
| ------- | --- | --- | --- |
| 89342   | 23  | 28  | 30  |
| --      | --  | --  | --  |
>
>In questo caso le **Features** sono : IAP, BD , ASD 

Alle **Features** si aggiunge un'altra colonna detta **Label** che contiene la variabile *target* della nostra *predizione* che vogliamo svolgere 

In questo caso una **Label** potrebbe essere se lo studente ha ricevuto o no la Lode alla fine del precorso di studi 

Possiamo costruire un *modello* sulla base dei dati storici che ci permetta di , dati in input le **Features** *predire* se lo studente in questione riceverà la lode o no
Avremo quindi che il modello potrà essere rappresentato da questa espressione : 
$$M(x_i) \rightarrow L\ \text{or}\ NL$$
Dove $x_i$ deve essere un record **nuovo** al modello

I dati su cui alleniamo il modello sono detti il **Training set** ( che per essere un *supervised learning* deve contenere anche la **Label** )

Quando la **Label** è un valore *discreta* abbiamo che il modello sta svolgendo un **task di classificazione** 

Per capire se il modello ha "imparato" correttamente dobbiamo verificare che predica correttamente su un insieme **nuovo** ( diverso dal **Training set** ) detto **Test set**

>[!note]
>In genere si dividono il data set in 2/3 *training set* e 1/3 *test set*

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
									X, y, test_size=0.33, random_state=42)
```

Per verificare che il modello predice correttamente nel caso *discreto* semplicemente calcoleremo l'accuratezza in base a quante volte da la risposta corretta ( in prativa contiamo il numero di volte che predice correttamente e la dividiamo per il numero di **Record** in input )

Nel caso di una **Label** *continua* il calcolo dell'accuratezza è differente ( quando dobbiamo predire un valore *continuo* si dice che il *modello* sta svolgendo un **task di regressione** )

In questo caso calcoleremo la *distanza* della predizione dal valore corretto 

In `sklearn` abbiamo la classe `KNeighborsClassifier` che è un modello *classificatore* che sceglie un gruppo a seconda della frequenza di vicini che ha ( lazy learner , ossia il training non fa nulla se non posizionare i dati all'interno di un database per poi essere confrontati con il dato in input ) , ossia : 

![[Drawing 2024-09-23 20.55.16.excalidraw]]

I dati all'interno del database hanno già la **Label** ( poichè siamo in *supervised learning* ) e quindi i dati sono già assegnati ad un gruppo quando vengono messi nel database

Ora dato un nuovo dato $?$ `KNeighborsClassifier` deciderà se assegnarlo ad una classe o ad un'altra se , dato $k$ il numero di elementi da considerare , vi sia una maggioranza tra quelli di un gruppo o di un'altro gruppo ( si sceglie un $k$ dispari per evitare situazioni di parità tra un gruppo un'altro ) 

>[!example]
![[Drawing 2024-09-23 21.01.34.excalidraw]]
>
>Con $k = 7$ avremo 5 elementi del gruppo blu e 2 del gruppo arancione , questo porterà a sciegliere il gruppo blu per quell'elemento

>[!note]
>Con $k=\infty$ il modello ritornerà sempre il gruppo con più elementi nel dataset
>Con un $k$ minimo potremmo essere influenzati da errori di campionamento dei dati
>

>[!note]
>Se non specifichiamo `KNeighborsClassifier` calcola la distanza euclidea , possiamo definire altri metodi modificando il valore di `metric`

```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Create the classifier
kNN = KNeighborsClassifier(n_neighbors=k)

# Train the classifier on train dataset
kNN.fit(X_train,y_train)

# Generate predictions on the test dataset
y_pred = kNN.predict(X_test)

# compute Accuracy between the y_test (real values) and the predicted values y_pred
acc = accuracy_score(y_true=y_test, y_pred=y_pred)

print (f"Accuracy {acc:.3f}")
```

L'accuratezza basandosi sulla distanza tra le **Feature** di un *oggetto* è soggetta ad errori come derivanti dal peso di ogni componente della **Feature**

>[!example]
>Potrebbe essere che una certa **Feature** abbia un valore molto alto in base alla sua unità di misura , questa quindi avrà molto più peso nel calcolo della distanza rispetto ad altre **Feature** con range minori 

Per risolvere questo ci basterà **normalizzare** i dati per fare questo utilizziamo un `MinMaxScaler()` che in pratica scala ogni **Feature** in un range tra 0 e 1

>[!note]
>Se sappiamo che i dati hanno una distribuzione gaussiana possiamo utilizzare invece `StandardScaler()`

```python
from sklearn.preprocessing import MinMaxScaler

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.33, random_state=42)

scaler = MinMaxScaler()
scaler.fit(X_train) # lo scaling si fa sul training set 

for k in range(1,11): # per trovare il migliore valore di k

    kNN = KNeighborsClassifier(n_neighbors=k)
    kNN.fit( scaler.transform(X_train), y_train ) # nel fare il modello si applica lo scaling trovato .trasform sul training dataset
    y_pred = kNN.predict( scaler.transform(X_test) ) # uso lo scaler trovato su X_train per fare la trasformazione del dataset di test

    # compute Accuracy
    acc = accuracy_score(y_true=y_test, y_pred=y_pred)
    print ("k: {:2d} | Accuracy {:.3f}".format(k,acc) )
```

Se sappiamo precisamente il domino dei dati potremmo definire una funzione di *scaling* custom ( che generalmente viene fatta "imparare" da un altro modello )

```python
def my_distance(a,b):
    return 10*abs(a[0]-b[0]) + abs(a[1]-b[1])

kNN = KNeighborsClassifier(n_neighbors = k, metric = my_distance)
```

Per velocizzare la ricerca scegliamo dei *rappresentanti* per ogni cluster di dati con cui confrontiamo i dati di input invece di cercare l'intero database