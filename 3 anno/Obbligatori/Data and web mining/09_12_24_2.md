---
publish: true
creation: 2024-12-16T13:00:00
---
# Semi-Supervised Classification

Nel **Semi-Supervised Learning** viene allenato un *calssifier* su un dataset formato nel seguente modo : 
+ Abbiamo $l$ istanze di cui conosciamo l'*etichetta*
+ Abbiamo $u$ istanze per cui non conosciamo l'*etichetta*

>[!note] 
>Generalmente $l \ll u$ 

Un approccio è quello di *predire* un'*etichetta* per le istanze di $u$ esucessivamente allenare un classificatore sull'intero dataset 
## Label Propagation

>[!info] Idea
>
>Ogni istanza in possessio di un'etichetta la propaga ai suo vicini


I *vicini* di una data istanza sono determinati sulla base di una *matrice di pesi* $W$ , dove $w_{ij}$ è la *similarità* tra gli oggetti $x_i$ e $x_j$ 

### Weight

Il peso $w_{ij}$ può avere due definizioni : 
+ Basato su *k-NN* : 
	$w_{ij} = 1$ se $x_i$ è tra i $k$ vicini più vicini , $0$ altrimenti 
+ Basato sulla *distanza* : 
	$w_{ij} = \exp\left ( -\frac{d^2_{ij}}{2\sigma^2} \right ) = \exp \left ( -\frac{|| x_i - x_j||^2}{2\sigma^2} \right )$ 
	Dove $\sigma$ è detto *length scale* ( iperparametro utilizzato per definire quanto simili consideriamo i punti in relazione alla loro distanza ) 

Ad ogni nodo assegnamo una *soft label* , ossia per ogni classe abbiamo una probabilità di appartenenza a quella determinata classe , queste vengono propagate a seconda di una **probabilità di transizione** $T_{ij}$ : $$T_{ij} = \frac{w_{ij}}{\sum_{k} w_kj}$$
>[!note] 
>In pratica i pesi $w_{ij}$ vengono normalizzati per tutti i pesi uscenti di $x_j$

### Example Algorithm

Facciamo che $Y$ sia $(l+u)\times C$ la matrice che mantiene le *soft label* di tutte le istanze , inizialmente la *label* per le istanze *non etichettate* non è importante e può quindi essere inizializzata ad un valore uniforme o randomico 

```pseudo
	\begin{algorithm}
	\caption{Label Propagation}
	\begin{algorithmic}
	\State Propaga : $Y \leftarrow TY$
	\State Normalizza le righe $Y$
	\State Ritorna alle label iniziali per i punti che avevano la label
	\State Ripeti fino a convergenza
	\end{algorithmic}
	\end{algorithm}
```

>[!example] 
>
>
>![[Pasted image 20241216135530.png]]
>```python
from sklearn.semi_supervised import LabelPropagation
>
>lp = LabelPropagation(kernel='rbf', n_neighbors=5, max_iter=100)
>lp.fit(X, y_10)
>
>y_prop = lp.label_distributions_[:,1]
># lp.transduction_ provide hard label assignment
>```
>
>![[Pasted image 20241216135539.png]]
# Web Seach and Ranking

>[!note] 
>Non all'esame

