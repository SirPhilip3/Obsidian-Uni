---
creation: 2024-09-23T13:52:00
tags:
  - appunti
---
**Supervised learning** : 

machine learning algo 

in : dati tabellari 

| 1   | 2   |
| --- | --- |
| -   | -   |
ogni riga un record -> info rigudanti una certa **istanza** -> ogni riga tot colonne -> **features**
caratterisitche che id un'istanza 

1. dato un oggetto come lo descrivo -> qual'è il vettore di *feaures* utili per descriverlo 

prediction task -> supervised learning

| Stude | Iap | BD  |
| ----- | --- | --- |
| 89723 | 23  | 25  |
| ??    | ??  | ??  |
vorrei predire se avrà o no la lode -> label -> variabile target

sulla base di uno storico dei dati possiamo decidere se lode o no -> modello predittore
*modello* : 
$$M(x_i) \rightarrow L\ \text{o}\ NL$$
dove $x_i$ è una riga **nuova**

Training data set -> storico da cui deduciamo un modello -> ha anche le etichette , label del risultato ( hanno o no preso la lode )

**task di classificazione** -> l'etichetta *label* è discreta 

per capire se è "bravo" -> serve un altro insieme di dati con le stesse feature di prima e istanze che non ho mai visto nel training , con relativa etichetta 

usiamo un'istanza di questo **test set** nel modello se ho y uguale a quello presente nel **test set**

feature devono identificare **univocamente** una riga del training set

se voglio predire una $y$ continua -> non posso misurare l'eguaglianza nel **test set** -> potrei avvicinarmi molto al dato reale -> vorrei avere comunque una accuracy alta

| M1  | M2  | y   |
| --- | --- | --- |
| 108 | 80  | 110 |
| 99  | 80  | 100 |
| 91  | 80  | 90  |
Se dovessimo scieglere con l'ugualglianza entrambi avrebbero accuracy 0% 
misurerò lo scarto tra il modello ed il valore reale 

**regressione** -> etichetta continua

per avere training e test -> separo dati storici in due parti 

>[!warning] 
>Meglio sempre separare il data set in training e test prima di fare qualsiasi cosa 
>
>Esempio se aggiungo una feature che include sia dati del training che test , quando lo divido e faccio un modello userà un po dei dati del test

k-Nearest-Neighbour

scielgo il gruppo a seconda di che etichetta più freqeunte trovo più vicino al dato che voglio raggruppare 

Il modello è il training set in un database e poi fai query nel database per trovare il set che risulta essere più vicino -> lazy learner -> il traing non fa nulla , di base deve solo memorizzare i dati all'intenro del database -> il modello può essere qualsiasi cosa 

![[DWM1.excalidraw]]
Se i dati sono divisi esattamente a metà ??? -> posso mettere il k dispari o risolvo sciegleiendo in modo random oppure mi baso sull'intero dataset :

es 
k = 6 
b = 3
r = 3
b_intero = 90%
r_intero = 10%

dovrei scieglere rosso poichè ho preso molti r rispetto a blu

per prendere una decisione devo avere una base forte per farlo -> non posso basarmi solo sulla distanza minima tra i due gruppi 

se k= infinito mi ritorna la classe più grande nel dataset 

supervised -> a tempo di training so l'etichetta corretta 

metric -> metodo con cui misuro la distanza tra due istnaze se p = 2 -> distanza euclidea 
k troppo piccolo -> soggetto a rumore 

potrei prendere un k grande ma pesare se una distanza è grande pesa poco etcc 

prob risolve i casi di parità

per ogni colonna -> differenza tra massimo e minimo

la distanza dipende dalla scala e dal range con cui sono composte le *feature* , una distanza per una fueture molto ampia ha molto più peso rispetto a tutte le altre , tutte dovrebbere contriubire allo stesso modo 

**Normalizziamo i dati**

su max 1 -> min_max_scaler
 
prima fit e poi trasform

fit kNeighbour su dati trasformati 

preparo lo scaling sul train e poi lo ri applico ai dati del test 

se i dati sono gaussiano usiamo standardscaler

Se so il dominio dei dati -> devo esplicitare il peso esplicitando una distanza "custom" ,possiamo imparare questa funzione 

per velocizzare la ricerca utilizzo dei rappresentanti dei cluster dei dati del data set per effettuare la ricerca 

seaborn

nome assi , legende + titolo