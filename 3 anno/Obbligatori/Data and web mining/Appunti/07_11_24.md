---
creation: 2024-11-07T12:13:00
tags:
  - appunti
---
cluster analysis

unsupervised learning , trovare gruppi di istanze opmogenee tra di loro

Kmeans -> primo algoritmo di clustering , lista di etichette grande come il dataset , ad ogni el associa un id per il cludter ( numeri non relativi al cluster ) , gli dobbiamo dire quanti cluster vogliamo

definiamo quando un clustering è buono o no . misura di similarità , quanto sono simili tra di loro 

alta similarità tra oggetti della stessa classe bassa tra quelli di classi diverse 

il true clustering non è noto a priori , il clustering può essere soggettiva utenti in base al gusto ex 

categorie algo :
+ esclusivo -> 1 el apppartiene ad un solo cluster
+ non esclusivo -> assegno perc di similarità a cluster diversi 
+ single level -> non ci sono altre relazioni tra isiemi 
+ gerarchici possiamo mettere assieme cluster a formare una gerachia -> doc naturalistico + doc storico = documentari gen -> dice qualcosa in più dei dati , possiamo decidere a che livello guardare 
+ distance based -> dobbiamo trovare distanza tra istanze 
+ connectivity based -> come sono connessi nel grafo -> quanti passi tra due etcc 
+ fullspace usano tutte le feture
+ subspace -> sottoinsieme di feature

ci sono algo che accettano dei vincoli tra istanze da accettare 

cluster possono avere forma arbitraria 

partitioning algo -> kmeans
gerarchico
densità

algoritmi basati su modelli dei dati 

---

trovare i cluster significa trovare dei centri , un punto a quale centro vorrei associarlo ? , 

misura di qualità dell'output -> vogliamo che i punti siano il più possibile vicini ai centri 
i a k centri (k cluster) , ogno id da Ci , ogni punto appartiene ad un cluster , c_i centro di quel cluser , sommo dist tra tutti i punti e c_i alla 2 , errore minore = direzione da seguire = più vicini sono 

algoritmo deve minimizzare questo errore 

ongi punto devo darlo a quello che minimizza l'errore 

assumiamo di sapere il numero di cluster

inizialmente prendiamo centri in modo casuale -> dati i centri per ogni punto lo do al cluster che minizza errore , per migliorare i centri devo minimizzare la funzione costo 

dati i cluster quali sono i miglieri centri -> media delle ordinate 

per ogni cluster prendo il baricentro dei punti

kmeans

tassellazione di koronohy

inizualmente voglio kmeans che trovi cluster reali ossia che le istanze siano veramente simili tra di loro

kmeans funziona bene per cluster sferici 

migliorie : 
partire da centroidi migliori -> possono indurre ad errore se scelti vicini tra di loro , possono rimanere vicini e non spostarsi 

kmeans++ -> come cambio l'inizializzazione , cerca di prednere punti distanti tra di loro , punti vicni con bassa prob lontani con più prob , per ogni punto dist dal suo centroide più vicino , gli do prob che dipende da distanza -> scielgo il prossimo centroide in base a questa prob , ricalcolo etcc... 

miglior k -> li provo tutti , mi fermo dove trovo il gomito -> aumento della sse marginale 

se il numero di cluster == n punti 0 errore 
molto usato x scala bene con dati grandi

dato k trovare clustering NP-Hard 

clustering gerarchico

arco = coppia di cluster collegati tra di loro , altezza degli archi la loro distanza 
dendrogramma

matrice di simiglianza calcolata su tutti i cluster , metto assieme le coppie più vicine  

agglomerativo -> da singoli cluster a grandi
divisvo da grande a piccoli 

misura della distanza -> euclidea ?? altre , la distanza è tra cluster complesso possiamo fare come SVM -> single linkage -> prendo i più vicini 
complete linkage > i più lontani
media delle distanze -> average linkage
distanza tra i centroidi 
ward -> calcola incremenot di sse 

linkage = distanza tra cluster

single -> mi basta che abbiano un punto molto vicino e li considero vicini anche se tutti gli altri sono più distanti, ti permette di seguire forme arbitrarie 

average favorisce classi di forma sferica + coplete +ward

 coplete +ward favoriscono più densità 

single favorisce forme allungate 

tenti di trovare tanti cluster e da quello cerchi di capire se i dati non sono sferici usi single -> single molto vloce