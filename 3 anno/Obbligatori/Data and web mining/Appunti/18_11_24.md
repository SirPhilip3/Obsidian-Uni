---
creation: 2024-11-18T13:58:00
tags:
  - appunti
---
**Clustering evaluation**

valutazione intrinsica -> non abbiamo y
valutazione estrinseca -> quando abbiamo qualche etichettetatura -> vale tutto ciò cha abbiamo detto per la classificazione 

**siluette coefficent** -> se quel singolo oggetto è calssificato correttamente -> se è molto simile dagli oggetti del suo cluster , molto dissimile dagli oggetti dell'altro cluster

a. intra class similarity -> media delle distanze tra tutti  -> deve essere minima

b. inter class dissimilarity -> voglio che ogg sia lontano dagli altri ->deve essere massima
1. distanza media dagli oggetti dell'altro cluster 
2. ripeto per ogni cluster 
3. minimo delle distanze medie -> voglio essere lontano dal cluster più vicino che ho 

silhuette -> b-a/max(b,a) -> più alto melgio il clustering \[-1,1] 

distanza assume che i cluster siano sferici 

visto che la misura è di un singolo oggetto possiamo fare ulteriori analisi dopo

non necessariamente rappresenta il numero di cluster

**extrinsic**

per alcuni oggetti sappiamo la label 
>[!warning] 
>quando treniamo un modello l'id non è relativo alla label reale 

come nella classificazione bianria possiamo creare confuzion matrix -> basata su *coppie* di oggetti , mi aspetto che se hanno stessa etichetta avranno stesso clusterid 

due misure : *rand statistic* (casi buoni / tutti i possibili ) *javvard coefficent* (ignoro i true negative, perchè avere tanti true negative è "facile" se ho tanti oggetti e pochi claster ho più prob che 2 ogg con diff cluster e diff label succeda) 

altra statistica weighted tp e tn sono pesati per la loro probabilità 

generlamente meglio chiedere più cluster in modo che siano più coesi tra di loro 

**Use case**

titoli sono collegati ??? 

distanza deve essere indipendente dal range -> correlazione lineare -> pearson correlation -> misura la distanza tra due punti https://en.wikipedia.org/wiki/Pearson_correlation_coefficient

generalmente preferibile clustering omogenei rispetto alla distanza 

flat cluster -> per ogni oggetto id del cluster , otenuto tagliando il clustering gerarchico in qualche modo 

**Artificial neural networks and deep leaning** 

imagenet dataset di immagini per testare deep learning

artificial neurons

legge media pesata dei suoi segnali > aggiunto un bias -> a questo input applico una funzione -> tutti neuroni stessa f , ciò fa comportare in modo diverso sono i pesi sugli archi entranti -> ioutput replicato su tutti gli altri neuroni

fitting sul peso degli archi 

pesi iniziali un numero casuale 

training -> ha un feedback istanza per istanza , teacher > sa qual'è la sua etichetta vera -> confronta con output della rete -> differenza tra le due è un peso che usiamo per insegnare -> ogni ciclo è un' *epoca* di allenamento 

errore aggiorna i pesi e bias 

processo di training per keras 

rete organizzata in layer -> tutti i neuroni dello stesso tipo 
loss function -> per calcolare la distanza 
