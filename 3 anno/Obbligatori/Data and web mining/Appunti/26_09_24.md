---
creation: 2024-09-26T12:10:00
tags:
  - appunti
---
progetto -> filtering dove l'etichetta non è presente o provare a predire valori mancanti

train.csv -> tra tain e test , test.csv solo per submission

---
divido il plane in 4 ed assegno ad ongi parte una lable -> se trovo un punto in una parte -> pred

**Alberi di decisione**

sequenza di test che facciamo sui dati -> nel caso precedente regola che decide in che soluzione devo arrivare 

esegue un test alla volta e raffina man mano la decisione

![[04_dw.excalidraw]]

algoritmi standard provano tutte le opzioni e poi scelgo l'albero migliore 

test può avere molti outcome

alberi binari

--- wine dataset

binary split -> posso dividere alberi con più split in più binari

bontà dello split ? -> prova split possibili , misura la qulaità e si prende il migliore 

qualsiasi plit può essere diviso in una catena di split binari , alberi con più split non hanno vantaggi rispetto ai binari

di solito feture <= di una certa soglia vero sx falso dx

algoritmo di Hunt ricorsivo , all'inizio trovare il nodo dell'albero poi la ricorsione deciderà i figli dx , sx 

1-7 -> ritorna il miglior nodo possibile (F<=T) prova ogni f per ogni treshold
quando trovo best split -> sx feature che sono <= soglia dx > -> richiamo funzione sui sottoalberi

8-10 -> se best split non divide meglio le calssi rispetto a senza split mi fermo -> 

best gain = 0 -> non significa che ho trovato per forza insieme puro -> potrei avere rami entrambi ugualmente peggio

mi fermo e ritorno una foglia 

ritorno una foglia se trovo qualche altre criterio di stop ( profondità etcc )

bestgain -> se abbastamza piccolo non mi conviene andare avanti  === 0 non è raro 

gain -> che vantaggio ha splittare ripetto a non ( accuracy di prima - di dopo = gain )

come misuro il gain influenza l'algoritmo 

se devo costruire una foglia che predizione devo mettere ?
	Errore -> complementare dell'accuracy -> predizione che mi da l'errore più piccolo 
	mu -> etichetta più presente nel dataset 
	Percentuale degli errori 100% - istanze che predico correttamente -> quelle con etichetta più frequenza
	Quando non ho discriminato nulla -> predizione random

Nodi interni -> misuro il beneficio che ho -> errore che avevo prima - quello che ho aggiungendo un nodo -> se io mettessi lì una foglia che errore avrei ? 

media pesata per dimension

meglio splitting b poichè almeno ho risolto metà dell'albero ,

in caso di regressione si guarda la dispersione ( scarto quadratico medio )

generalmente a meno che non ho 2 punti di classi diverse con le stesse feture -> etichetta diversa -> un albero di decisione può arrivare sempre ad una accuracy del 100% , nel caso pessimo folgie con una sola istanza 

A meno che non lo stoppo prima

potrebbe essere overfitting ,con una sola foglia -> supporto di un solo punto 

