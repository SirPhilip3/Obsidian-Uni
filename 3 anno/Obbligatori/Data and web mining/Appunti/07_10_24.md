---
creation: 2024-10-07T14:06:00
tags:
  - appunti
---
**Model Overfitting** : Breast_Cancer

Sul test ho un calo di accuracy -> *overfitting* , 
mancaza di istanze rappresentative -> tutto il fenome che vogliamo descrivere sia descritto bene dal train ( es predire music , quando si aggiunge una canzone sul train non era presente )

Complessità del modello :
+ troppo complesso -> overfitting

>[!example] 
>Predizione sul prezzo di uno stock 
>
>Predizione random : 50/50
>
>Che salga/cada nei prossimi 10 giorni : 5% >=8
>
>avendono 50 prob che 1 indovini 8/10 $1-(1-0.05)^{50} = 0.94$ ( (1-0.05)^{50} tutti sbagiano ) è sicuro che almeno uno faccia la predizione corretta 

Ottenere un modello semplice : 

Utilizziamo un *validation set* -> voglio cercare di capire come si comporta il modello su dati che non ha mai visto -> 60 training , 20 validation , 20 test

>[!warning] 
>Non possiamo utilizzare il test perchè questo rappresenta un caso reale

Validation simuliamo dati che non sono mai stati visti prima, alleno tuti i modelli su training , misuro performance su validation , prendo modello che performa meglio sul validation

training : alleno il modello
validation : stimare i parametri migliori del modello (numero di foglie)
test : stimare accuratezza di un modello su dati mai visti

Una volta deciso i parametri : 
+ prendo tutto il training e faccio il training con il parametro migliore trovato
+ restituire il modello 

**pruning**

Non voglio modello complesso se ho 2 modelli 1 semplice 1 complesso con errore comparabile scielgo il più semplice

errore di generalizzzione 

pre -> prima della costruzione dell'albero
pro -> tolgo i sottoalberi

Prendo un modello complesso e tolgo dei sottoalberi non utili -> cercando di stimare l'errore che farò togliendolo , se rimane uguale o aumenta di poco taglio

Errore : sommo errore di ogni istanza e divido per numero di  istanze > media degli errori 

errrore di generalizzazione -> errore su dati mai visti
errore sul mio dataset + $\alpha * \text{complexity}$ -> più modello è complesso più sbaglierò

come misuro complessità ( numero foglie/dimensione dataset se vicino ad 1 -> complesso ( oppure bit che mi servono per codificarlo ) ) e touning $\alpha$

touning di $\alpha$

peso > da più o meno importanza alla complessità

se = 1 l'errore aumenta di 1/D 
+ aggiungere una foglia è conveniente se sono accurato di almeno due istanza in più 
+ non convene se l'errore non cambia
+ non conviene se l'errore è ridotto di solo un'istanza

se pruno la foglia è la media/moda delle etichette

in sklear -> errore somma entropia di tutte le foglie , complessità il numero di foglie

fa proning quando ho stesso errore del sottoalbero completo , con alfa sufficentemente grande 
**alfa effettivo** ? 

punto migliore in cui ho prunato un mo ma non ho impattato troppo l'errore 

elimina sottoalberi che specializzano rumore

**Implementazione** : 

Calcolo del gain e best split per il caso della *regressione*

**errore** : MSE
foglia -> media delle label
internal node 

per ogni feature e soglia una sola scansione del dataset 

istanza dx + istanze sx = ist tot

somma = media \* numero di istanze 

non ci interessa moltiplicare per 1/d perchè è una costante 
non ci interessa $|D|\mu^2$ perchè è una costante

somma comulativa evita la riscansione , per ogni possibile split

feature uguali consecutive -> quella più a destra , lo split calcolato tra quella piu a destra e quella dopo