---
creation: 2024-10-31T12:06:00
tags:
  - appunti
---
feature con valori unici -> se hanno un ordine -> trasformazione in numerico secondo l'odine , in alberi ok -> perchè fa solo confronti con <= , invece in regressione lineare questa ha valore maggiore secondo l'ordine dei dati 

non uso test per calcolare statistiche di alcun tipo

predittore **baseline** -> se il modello fa peggio X

categoria ad id numerico qualsiasi -> sempre da fare visto che accuracy calcolata con uguaglianza , non ha importanza l'ordine 

oltre accuracy , ha più senso quando ho lable non solo binarie , 

confusion matrix , etichetta vera dei dati vs quella predetta, diag = corrette 

best = solo numeri sulla diag 

altre misure dell'accuracy : 
+ precisione in classe c -> una precisione per ogni classe , quanto sono affidabile quando dico una certa classe ( 100% solo quando il predittore è sicurissimo )
+ recall -> tutte le volte che avevo questa classe quante volte l'ho trovata , complementare della precisione , quante me ne sono perso ( se dico sempre la classe 100% )

1 numero per precision e recall
+ F-mesure : media armonica è media pressimistica più vicina al vlaore più basso dei due , più alto possibile = better
+ F-mesure wheighted -> dico quanto mi interessa una dei due

numero unico per tutte le classi , 2 modi :
+ media -> precision macro , molta importanza a classi rare 
+ weighted -> media pesata , pesa di più dove ho piu istanze ( tutte istanze ugualmente importanti )

per migliorare nelle classi rare 

posso spostare focus dell'algoritmo su classi rare pagando un po in quelle con più "accuracy"

cost sensitive learning , ogni tipologia di errore = un peso , ottimizziamo la somma pesate degli errori 

peso a ciascuna classe , se sbagli toxic err = 10

generalmente il peso è inversamente prop della frequenza , bilancia il dataset 

ricampionamento / eliminazione di istanza 

binarizzare il dataset -> mi distingue negative dagli altri e poi un classificatore ad hoc per gli altri 
se il calssificatore globale sarebbe troppo complesso 

per ogni istanza posso avere probabilità di predizione , 1 istanza 85% di 0 15% di classe 1 , cosa avevo in quella foglia , soglia di decisione a 0.5 , se non voglio mancarmi nessun positivo la sogli sarà più bassa , iperparametro 

Reciever operating characteristic 

plot algoirtmo al variare della soglia di predizione , vedo come cambiano true positive e false positive 

mi permette di scegliere la soglia ottimale del modello , l'app ti dice cosa puoi tollerare , 

il modello ideale è massimamente true positive , curva più in alto possibile = meglio 
random = nella diagonale 

area sotto della curva -> perfetta A = 1

soglie solo quelle che mi portano ad un cambiamento di scelta finale 

uso un modello meno costoso per avere un subset dove usare un modello più costos
cascading classifier
stage classifier, uso predizione di un classifier come feature di un altro stadio