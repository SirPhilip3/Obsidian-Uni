---
tags:
  - appunti
creation: 2024-12-02T14:01:00
---
10 classi invece che bianrio :
non abbiamo salti tra layer non consec e tutti nodi collegati tra di loro
output della rete ? -> 1 nueoroen nin output layer per ogni classe 

ogni nuorre si scpecializza su una classe 

funzione di attivazione : ????

sigmoide su ogni nodo tante probabilità -> quello con prob maggiore prediciamo quello 

La somma dei segnali da ogni neurore in putput deve dare 1 -> normalizzazione 

**SoftMax** : attivazione non sta dentro un neurone ma sta fuori da tutti i neuroni -> ci serve la somma di tutti gli altri e^segnael / somma degli altri e 

esalata i valori alti 

considerazioni per la funzione : ottimizzazione , facilità a livello numerico 

categorical cross entropy -> versione categirica della binary cross entropy 