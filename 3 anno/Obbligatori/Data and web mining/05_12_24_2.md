---
publish: true
creation: 2024-12-07T18:17:00
---
# 1D Convolution

*1D convolution* può essere utilizzata per *time series* 

In questo caso i filtri devono essere costruiti considerando il numero di elementi che prende in input come una finestra usata per predire il prossimo valore 

>[!example] 
>**Stock price prediction** 
>
>![[Pasted image 20241209094639.png]]
>
>Visto che vogliamo avere una finestra lunga 100 giorni e volgiamo predire il prossimo valore dobbiamo creare un insieme di input $x$ , le **feature** , composto di 100 giorni e un insieme *risposta* $y$ composto del giorno sucessivo da predire : 
>
>```python
>def prepare (y,w):
>    XX = np.array( [ y[i:i+w] for i in range(len(y)-w) ] ) # 100 feature
>    YY = np.array( y[w:]) # 1 output
>    return XX, YY
>
>window = 100
>train_x, train_y = prepare(apple_closing, window)
>```
>
>La rete sarà la seguente 
>```python
>model = Sequential()
>
>model.add( Input(shape=(window,1)) ) # window = 100
>
>model.add( Conv1D(4, 5) ) # 4 filtri grandi 5 
>model.add( Activation("relu") )
>model.add( MaxPooling1D(2) )
>
>model.add( Conv1D(4, 5)) 
>model.add( Activation("relu") )
>model.add( MaxPooling1D(2) )
>
>model.add( Conv1D(8, 5) )
>model.add( Activation("relu") )
>model.add( MaxPooling1D(2) )
>
>model.add( Conv1D(8, 5) )
>model.add( Activation("relu") )
>model.add( MaxPooling1D(2) )
>
>model.add( Flatten() )
>model.add( Dense(1) )
>
># finalize the network
>model.compile( optimizer="rmsprop",
>               loss='mse',
>               metrics=['mean_absolute_error'] )
>
>model.summary()
>```
>![[Pasted image 20241209095407.png]]
>![[Pasted image 20241209095442.png]]
# Overfitting e Best Practices

Generalmente **overfitting** è dato da :
+ Un numero maggiore di parametri ( *pesi* ) rispetto alle istanze presenti nel *training set*
+ Il *validation set* non rappresenta il *training set* 

>[!note] 
>Di solito si aggiunge un *development set* molto piccolo usato per valutare manualmente la rete 
## Data augmentation

Se abbiamo un modello che non possiamo semplificare necessitiamo di aumentare il numero di data in input al modello 

Questo può essere fatto facilmente con le *immagini* , basterà ruotare , traslare o scalare l'immagine in modo randomico 

Per dati relativi ad altri domini la generazione di ulteriori dati non è così facile 

>[!example] 
>
>```python
>train_datagen = ImageDataGenerator( rescale=1./255,
>                                    rotation_range=40,
>                                    width_shift_range=0.2,
>                                    height_shift_range=0.2,
>                                    shear_range=0.2,
>                                    zoom_range=0.2,
>                                    horizontal_flip=True,
>                                    fill_mode='nearest', 
>                                    validation_split= .2,)
>```
>
>![[Pasted image 20241209101125.png]]

>[!note] 
>In questo modo sarà quasi impossibile che la *rete* veda la stessa immagine più di una volta

## Dropout

**Dropout** "muta" temporaneamente , a tempo di training , un numero casuale di neuroni all'interno di un layer , in questo modo costringe il prossimo layer a non fare affidamento solo su quegli output e a trovare strade alternative per raggiungere un buon **loss** 

>[!note]
>Generalmente la percentuale di *dropout* è tra $0.25$ e $0.5$

>[!important] 
>Il *dropout* non ha alcun effetto a tempo di *testing*

>[!note] 
>In `Keras` viene aggiunto come un layer addizzionale , tipicamente prima dell'ultimo *layer denso* 
>```python
>model.add( Flatten() )
>model.add( Dense(64) )
>model.add( Activation("relu") )
>### DROPOUT
>model.add( Dropout(0.5) )
>
>model.add( Dense(10) )
>model.add( Activation("softmax") )
>```

## Transfer Learning

Possiamo utilizzare reti pre-trainate e specilaizzarle per la nostra task

Generalmente vengono elimitani gli ultimi layer densi e sostituiti con layer per svolgere il nostro task specifico , "frezzando" i pesi della rimanente parte della rete , in questo modo la nostra rete dovrà imparare solo i pesi relativi all'ultima parte della rete 

>[!example] 
>Trainare un calssificatore di immagini da 0 richiede il possesso di enormi qunatità di immagini su cui trainare la rete , se volessimo solo riconoscere specificatamente alcune immagini , utilizziamo la rete pre-treinata e sostituiiamo gli ultimi *layer* con i nostri specifici *layer* e trainiamo solo quei pesi

# Deep Larning Workflow

#todo

