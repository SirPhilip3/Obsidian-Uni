---
creation: 2024-11-19T12:04:00
tags:
  - appunti
---
**HTTP**

a comand

URI (universal resource identifier) -> id di risorse , non dice dove trovarlo -> URL  locator 

uri :
+ schema : che protocollo devo usare, implicitamente specifica la porta 
+ authority -> indirizzo dove sta la risorsa , se preceduto da @ indica un utente su quell'authority dopo authority può essereci la porta da dove connettersi
+ path cartelle in formato unix dove trovare il contenuto , se non gli dice nulla return content di default
+ query : ?parametro=value 
+ fragment -> determina il pezzo della pagina da visualizzare

@ ha priority -> authority dopo la 

`ftp://cnn.example.com&story=breaking_news@10.0.0.1/top_story.htm` 
si connette a 10.0.0.1 con username cnn.example.com&story=breaking_news e ritorna rop_story.htm con protocollo ftp 

**HTML**

dynamic pages -> codice server side attraverso Common gateway interface CGI , alla ricezione del file qullo che è prodotto

client side code -> uso di js 

usa CSS per lo stile 

Caricare una pagina HTML -> 

HTTP -> hyper text transfer protocol , collegato tramite tcp e poi comandi per prendere le pagine

richiesta HTTP usa : 
+ metodo 
+ URI
+ version
+ headers -> mime

respose ha uno status line con codici di errore ,header e mime

+ GET prendi la pagina 
+ HEAD prendi gli header della pagina , per verificare se è stata modificata etcc
+ POST upoload di mime

Headers :
+ User-Agent : ha senso per il server sapere che utente si collega
+ Referrer : da dove viene il traffico
+ Host : il dominio che client richiede
+ Server : info riguardante al server

Status code : convenzione normale 200 ok , 300 doc not available , 400 http req error , 500 server error

persistent connection , connection: keep alive -> non chiudere la connessione se volgiamo fare get di più cose nello stesso server altrimenti connessione ogni volta

` Keep−Alive : timeout=15, max=100`
100 chiamate se non facciamo nulla per 15s end

HTTP è stateless -> funziona richiesta per richiesta , mantenaiamo uno stato tramite header : cookies -> info generata dal server , messo in un header quando ci connettiamo dinuovo allo stesso server

tipi di cookies : 
+ gestione della sessione
+ personalizzazione
+ tracking : profiling user activities 

è possibile rubare sessioni se rubiamo i cookie

Accelerare perfomance -> cache intermedie -> possiamo mettere un proxy nella rete locale o chi offre il servizio -> proxy server sta nel mezzo , non andare direttamente al sito ma prima andare da lui che usa SOCS per connettersi al server, mantene una cache

proxy potrebbe vedere traffico non cifrato 

abbiamo anche header che ci dicono se possiamo o no cachare il sito e come la possiamo gestire 
+ cache-control : no-store , max-age ,
+ if-modified-since : ritorna la pagina solo se non è cambiata da una certa data 

reverse-proxy ->trasparente all'utente e sta davanti al server , una cache che permette di risparmiare chiamate al backend , traffico per utenti è identico

**http 2.0** 

protocollo binario , riduce quantità di info 

pagina scomposta in frame , quando facciamo richiesta server può restituire frame in parallelo , per evitare head of line blocking 

gestito dal server
meccanismo di push -> senza che noi le chiadiamo 